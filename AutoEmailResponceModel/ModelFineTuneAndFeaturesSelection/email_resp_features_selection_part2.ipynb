{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.2.post1\n",
      "0.81\n",
      "0.25.3\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, sys\n",
    "curruser = os.environ.get('USER')\n",
    "sys.path.insert(0, './../src/')\n",
    "sys.path.insert(0, '/home/{}/notebook/support_library/'.format(curruser)) \n",
    "sys.path.insert(0, '/home/{}/python35-libs/lib/python3.5/site-packages/'.format(curruser))\n",
    "# sys.path.insert(0, '/home/ufimtsev1-ys_ca-sbrf-ru/notebooks/labdata/lib/')\n",
    "\n",
    "import re \n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "# from sshloader import Ssh\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 1000\n",
    "\n",
    "\n",
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "from csv import QUOTE_ALL \n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "# tqdm_notebook.pandas()\n",
    "\n",
    "import imblearn\n",
    "import feature_importance\n",
    "\n",
    "import sklearn\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedShuffleSplit, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, \\\n",
    "                            classification_report, precision_score, \\\n",
    "                            recall_score, roc_curve, precision_recall_curve, \\\n",
    "                            average_precision_score, make_scorer, confusion_matrix, get_scorer\n",
    "            \n",
    "from sklearn.preprocessing import binarize, OneHotEncoder\n",
    "\n",
    "\n",
    "print(sklearn.__version__)\n",
    "print(xgboost.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_pred, y, average='binary'):\n",
    "    print(classification_report(y, y_pred, digits=5, ))\n",
    "    recall = recall_score(y, y_pred, average=average)\n",
    "    precision=precision_score(y, y_pred,average=average)\n",
    "    f1=f1_score(y, y_pred,average=average)\n",
    "    \n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_impotance(model, X_train, count_top_features = 20):\n",
    "    imp=model.feature_importances_\n",
    "    names=X_train.columns\n",
    "    imp, names=map(list, zip(*sorted(zip(imp, names))[::-1][:count_top_features]))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(9,12))\n",
    "    #ax = plt.axes()\n",
    "    sns.barplot(x=imp, y=names, palette=sns.color_palette('YlGn', 2), ax=ax)\n",
    "    ax.set_title('Top ' + str(count_top_features) + ' important features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data for Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 59s, sys: 1min 6s, total: 14min 5s\n",
      "Wall time: 14min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "csvpath = Path.joinpath(Path(os.getcwd()),'csv','data4train_sampled_60pct.csv')\n",
    "df_part = pd.read_csv(csvpath, encoding='cp1251', sep=';', compression='gzip')\n",
    "\n",
    "# df_part = pd.read_csv(filepath_or_buffer = csvpath, sep = ';', compression = 'gzip', engine='python',\n",
    "#                  dtype = {'target' : np.int32, 'OPF_IP': np.float32 ,'OPF_OOO': np.float32 ,'OPF_Other': np.float32 ,'ab_borrowed_capital': np.float32 ,'ab_immobilized_assets': np.float32 ,'ab_losses': np.float32 ,'ab_own_capital': np.float32 ,'acquiring_mobile': np.float32 ,'acquiring_torg': np.float32 ,'acreditiv': np.float32 ,'active_flg': np.float32 ,'all_prod_deals_completed': np.float32 ,'all_prod_deals_created': np.float32 ,'arenda_seyf': np.float32 ,'bank_straxovanie_imush': np.float32 ,'bank_straxovanie_lich': np.float32 ,'bank_straxovanie_otvet': np.float32 ,'branch_cnt': np.float32 ,'campaign_nm': np.float32 ,'cash_management': np.float32 ,'corp_cards': np.float32 ,'corp_cards_prod_deals_completed': np.float32 ,'corp_cards_prod_deals_created': np.float32 ,'corporate_cards': np.float32 ,'cred_application_cnt': np.float32 ,'cred_sdo': np.float32 ,'credit': np.float32 ,'credit_prod_deals_completed': np.float32 ,'credit_prod_deals_created': np.float32 ,'dbo': np.float32 ,'deposit': np.float32 ,'deposit_sertificat': np.float32 ,'deposits': np.float32 ,'depozit_prod_deals_completed': np.float32 ,'depozit_prod_deals_created': np.float32 ,'egr_org_id': np.float32 ,'egrul_org_id': np.float32 ,'einvoicing': np.float32 ,'email': np.float32 ,'factoring': np.float32 , 'fot_balance': np.float32, 'founders_all_cnt': np.float32 ,'founders_fl_cnt': np.float32 ,'founders_foreign_ul_cnt': np.float32 ,'founders_ul_cnt': np.float32 ,'fresh_user': np.float32 ,'garantee_gos': np.float32 ,'garantee_kontract': np.float32 ,'garantee_other': np.float32 ,'gis_bank_payment_flg': np.float32 ,'gis_card_payment_flg': np.float32 ,'gis_cash_payment_flg': np.float32 ,'gis_internet_merchant_flg': np.float32 ,'gis_internet_payment_flg': np.float32 ,'gis_merchant_cnt': np.float32 ,'gis_network_flg': np.float32 ,'gis_opt_merchant_flg': np.float32 ,'gis_production_merchant_flg': np.float32 ,'gis_rosn_merchant_flg': np.float32 ,'industry': np.float32 ,'inkass': np.float32 ,'insure_prod_deals_completed': np.float32 ,'insure_prod_deals_created': np.float32 ,'integrum_lower_bound': np.float32 ,'invest_kredit': np.float32 ,'ip_flg': np.float32 ,'konversion': np.float32 ,'kpp_regions_cnt': np.float32 ,'last_click_all_cnt_m11': np.float32 ,'last_click_all_cnt_m21': np.float32 ,'last_click_all_cnt_m31': np.float32 ,'last_click_day_cnt_m11': np.float32 ,'last_click_day_cnt_m21': np.float32 ,'last_click_day_cnt_m31': np.float32 ,'last_open_all_cnt_m11': np.float32 ,'last_open_all_cnt_m21': np.float32 ,'last_open_all_cnt_m31': np.float32 ,'last_open_day_cnt_m11': np.float32 ,'last_open_day_cnt_m21': np.float32 ,'last_open_day_cnt_m31': np.float32 ,'license_cnt': np.float32 ,'main_inn': np.float32 ,'main_kpp': np.float32 ,'main_organization_id': np.float32 ,'max_zp_empl_cnt': np.float32 ,'merch': np.float32 ,'merch_prod_deals_completed': np.float32 ,'merch_prod_deals_created': np.float32 ,'min_zp_empl_cnt': np.float32 ,'ns_servis': np.float32 ,'ns_terminal': np.float32 ,'oborot_kredit': np.float32 ,'obsluzh_rts_rur': np.float32 ,'obsluzh_rts_val': np.float32 ,'overdraft_kredit': np.float32 ,'products_lizing': np.float32 ,'proekt_finans': np.float32 ,'rko': np.float32 ,'salary': np.float32 ,'salary_prod_deals_completed': np.float32 ,'salary_prod_deals_created': np.float32 ,'samoinkass': np.float32 ,'spec_acc': np.float32 ,'stoplist': np.float32 ,'target': np.float32 ,'tb_Centralno_Chernozemnyj': np.float32 ,'tb_Dalnevostochnyj': np.float32 ,'tb_Moskovskij': np.float32 ,'tb_Povolzhskij': np.float32 ,'tb_Severo_Zapadnyj': np.float32 ,'tb_Uralskij': np.float32 ,'tb_Volgo_Vyatskij': np.float32 ,'total_count_dt': np.float32 ,'total_count_dt_3m': np.float32 ,'total_count_dt_year18': np.float32 ,'total_count_kt': np.float32 ,'total_count_kt_3m': np.float32 ,'total_count_kt_year18': np.float32 ,'ul_org_id': np.float32 ,'valuta_control': np.float32 ,'veksel': np.float32 ,'zarplat_projects': np.float32, 'sum_open_click_camp': np.float32, 'ul_kopf_cd': np.float32 },   \n",
    "#                  usecols = lambda columns : columns not in ['text', 'text_norm', 'inn', 'kpp', 'organization_id', 'email','campaign_nm', 'idx', 'fresh_user', 'complicity_type', 'ogrn', 'sum_open_click_camp'] \n",
    "#                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(r'.*_m\\d{1}1')\n",
    "pattern.findall('diff_lcl_fo_m11')\n",
    "ftcols = [col for col in list(df_part.columns) if '_FT_' in col]\n",
    "respcols = [col for col in list(df_part.columns) if len(pattern.findall(col))!=0]\n",
    "ml360cols = list(set(list(df_part.columns)) - set(respcols) - set(ftcols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take into account FastText vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train XGBoost: Add Features with FastText Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(df_part.drop(['target'], axis=1), df_part.target, \n",
    "                 random_state=42, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost' Parameters Optimization and FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(random_state=42, n_jobs=40, tree_method='hist',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pipeline dictionary for optimization with CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg, pos = df_part.target.value_counts().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale_pos_weight = (neg/pos)\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define parameter distribution over which to perform CV\n",
    "\n",
    "param_dist = {\n",
    "    \"clf__n_estimators\":                  [400, 500, 800, 1000],\n",
    "    \"clf__learning_rate\":                 [0.005, 0.01, 0.04, 0.08],\n",
    "    \"clf__num_leaves\":                    [64, 128, 256, 512],\n",
    "    \"clf__min_data_in_leaf\":              [20, 50, 100, 250],\n",
    "    \"clf__colsample_bytree\":              [0.5, 0.7, 0.8, 1.],\n",
    "    \"clf__scale_pos_weight\":              [2.041, 1.5, 1.2, 1.],\n",
    "    \"clf__max_bin\":                       [255, 230, 200, 180],\n",
    "    \"clf__max_depth\":                     [5, 6, 8, 10],\n",
    "    'clf__min_child_samples':             [20, 40, 100],\n",
    "    'clf__min_child_weight':              [1e-5, 1e-3, 1e-2, 1e-1, 1.],\n",
    "    'clf__feature_fraction':              [0.7, 0.8, 0.9, 1],\n",
    "    'clf__bagging_fraction':              [0.2, 0.5, 0.8, 1.],\n",
    "    'clf__bagging_freq':                  [0, 10, 20, 40],\n",
    "    'clf__lambda_l1':                     [0, 1e-3, 1e-2, 1e-1],\n",
    "    'clf__lambda_l2':                     [0, 1e-3, 1e-2, 1e-1],\n",
    "    'clf__n_jobs':                        [20, 20, 20, 20],\n",
    "    'clf__tree_method':                   ['hist', 'hist', 'hist', 'hist']\n",
    "    #'clf__is_unbalance':             [True, False]\n",
    "}\n",
    "\n",
    "n_iter_search = 3 # Define number of search iterations\n",
    "n_folds = 6 # Define number of CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = StratifiedShuffleSplit(n_splits=n_folds, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', classifier),\n",
    "     ])\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=n_iter_search, cv=folds, \n",
    "                                   scoring='recall', n_jobs=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train = df[respcols+ml360cols].drop(['target'], axis=1)\n",
    "# y_train = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "random_search.fit(X_train.astype(dtype=np.float32), y_train)\n",
    "\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))      \n",
    "print(\"\\nBest Score = \" + str(random_search.best_score_))\n",
    "print(\"\\nBest Parameters = \" + str(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit cls with the best params selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = pipeline.set_params(clf__n_estimators                 = random_search.best_params_['clf__n_estimators'],\n",
    "                                 clf__learning_rate                = random_search.best_params_['clf__learning_rate'],\n",
    "                                 clf__num_leaves                   = random_search.best_params_['clf__num_leaves'],\n",
    "                                 clf__max_bin                      = random_search.best_params_['clf__max_bin'],\n",
    "                                 clf__max_depth                    = random_search.best_params_['clf__max_depth'],\n",
    "                                 clf__scale_pos_weight             = random_search.best_params_['clf__scale_pos_weight'],\n",
    "                                 clf__colsample_bytree             = random_search.best_params_['clf__colsample_bytree'],                                 \n",
    "                                 clf__min_child_samples            = random_search.best_params_['clf__min_child_samples'],\n",
    "                                 clf__min_data_in_leaf             = random_search.best_params_['clf__min_data_in_leaf'],\n",
    "                                 clf__min_child_weight             = random_search.best_params_['clf__min_child_weight'],\n",
    "                                 clf__feature_fraction             = random_search.best_params_['clf__feature_fraction'],\n",
    "                                 clf__bagging_fraction             = random_search.best_params_['clf__bagging_fraction'],\n",
    "                                 clf__bagging_freq                 = random_search.best_params_['clf__bagging_freq'],\n",
    "                                 clf__lambda_l1                    = random_search.best_params_['clf__lambda_l1'],\n",
    "                                 clf__lambda_l2                    = random_search.best_params_['clf__lambda_l2'],\n",
    "                                 clf__n_jobs                       = 40,\n",
    "                                 clf__tree_method                  = random_search.best_params_['clf__tree_method']                                 \n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train.astype(dtype=np.float32), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test.astype(dtype=np.float32))\n",
    "\n",
    "recall_ts, precision_ts, f1_ts =  get_metrics(y_pred.astype(int), y_test.astype(int))\n",
    "                                                  \n",
    "print('Hold Out: ')\n",
    "print('Precision: %7.5f, Recall: %7.5f, F_1: %7.5f' % \n",
    "(precision_ts, recall_ts, f1_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(classifier, './pkl/xgb_cls_tuned_pipe_wFT_200606.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LightGBM' Parameters Optimization and FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgm=LGBMClassifier(seed=42, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = StratifiedShuffleSplit(n_splits=n_folds, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', lgm),\n",
    "     ])\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=n_iter_search, cv=folds, \n",
    "                                   scoring='recall', n_jobs=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "random_search.fit(X_train.astype(dtype=np.float32), y_train)\n",
    "\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))      \n",
    "print(\"\\nBest Score = \" + str(random_search.best_score_))\n",
    "print(\"\\nBest Parameters = \" + str(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit cls with the best params selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgm    = pipeline.set_params(clf__n_estimators                 = random_search.best_params_['clf__n_estimators'],\n",
    "                             clf__learning_rate                = random_search.best_params_['clf__learning_rate'],\n",
    "                             clf__num_leaves                   = random_search.best_params_['clf__num_leaves'],\n",
    "                             clf__max_bin                      = random_search.best_params_['clf__max_bin'],\n",
    "                             clf__max_depth                    = random_search.best_params_['clf__max_depth'],\n",
    "                             clf__scale_pos_weight             = random_search.best_params_['clf__scale_pos_weight'],\n",
    "                             clf__colsample_bytree             = random_search.best_params_['clf__colsample_bytree'],                                 \n",
    "                             clf__min_child_samples            = random_search.best_params_['clf__min_child_samples'],\n",
    "                             clf__min_data_in_leaf             = random_search.best_params_['clf__min_data_in_leaf'],\n",
    "                             clf__min_child_weight             = random_search.best_params_['clf__min_child_weight'],\n",
    "                             clf__feature_fraction             = random_search.best_params_['clf__feature_fraction'],\n",
    "                             clf__bagging_fraction             = random_search.best_params_['clf__bagging_fraction'],\n",
    "                             clf__bagging_freq                 = random_search.best_params_['clf__bagging_freq'],\n",
    "                             clf__lambda_l1                    = random_search.best_params_['clf__lambda_l1'],\n",
    "                             clf__lambda_l2                    = random_search.best_params_['clf__lambda_l2'],\n",
    "                             clf__n_jobs                       = 40,\n",
    "                             clf__tree_method                  = random_search.best_params_['clf__tree_method']                            \n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgm.fit(X_train.astype(float), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = lgm.predict(X_test.astype(dtype=np.float32))\n",
    "\n",
    "recall_ts, precision_ts, f1_ts =  get_metrics(y_pred.astype(int), y_test.astype(int))\n",
    "                                                  \n",
    "print('Hold Out: ')\n",
    "print('Precision: %7.5f, Recall: %7.5f, F_1: %7.5f' % \n",
    "(precision_ts, recall_ts, f1_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(lgm, './pkl/lgbm_cls_tuned_pipe_wFT_200606.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier' Parameters Optimization and FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import scale, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfcls = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp=SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_train_meta=pd.DataFrame(imp.fit_transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define parameter distribution over which to perform CV\n",
    "\n",
    "param_dist = {\n",
    "    \"clf__n_estimators\":                  [400, 500, 800, 1000],\n",
    "    \"clf__max_leaf_nodes\":                [128, 256, 512, 1024],\n",
    "    \"clf__min_weight_fraction_leaf\":      [0, 0.05, 0.1, 0.4],\n",
    "    \"clf__max_depth\":                     [6, 8, 10, 14],\n",
    "    'clf__max_features':                  [0.7, 0.8, 0.9, 1],\n",
    "#     'clf__max_samples':                   [0.7, 0.8, 0.9, 1],\n",
    "    'clf__min_impurity_decrease':         [1.e-9, 1.e-7, 1.e-5, 0.0],\n",
    "    'clf__n_jobs':                        [20, 20, 20, 20],\n",
    "    'clf__class_weight':                  [{0:1,1:1},{0:1,1:2},{0:1,1:4},{0:1,1:6}],\n",
    "    'clf__bootstrap':                     ['true', 'true', 'true', 'true'],\n",
    "    'clf__criterion':                     ['gini', 'gini', 'gini', 'gini']\n",
    "    #'clf__is_unbalance':             [True, False]\n",
    "}\n",
    "\n",
    "n_iter_search = 3 # Define number of search iterations\n",
    "n_folds = 6 # Define number of CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = StratifiedShuffleSplit(n_splits=n_folds, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', rfcls),\n",
    "     ])\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=n_iter_search, cv=folds, \n",
    "                                   scoring='recall', n_jobs=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "random_search.fit(X_train_meta.astype(dtype=np.float32), y_train)\n",
    "\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))      \n",
    "print(\"\\nBest Score = \" + str(random_search.best_score_))\n",
    "print(\"\\nBest Parameters = \" + str(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit cls with the best params selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfcls = RandomForestClassifier()\n",
    "pipeline = Pipeline([\n",
    "    ('clf', rfcls),\n",
    "     ])\n",
    "rfcls  = pipeline.set_params(clf__n_estimators                 = 800,\n",
    "#                              clf__max_leaf_nodes               = 512,\n",
    "#                              clf__min_weight_fraction_leaf     = 1e-4,\n",
    "                             clf__max_depth                    = 6,\n",
    "#                              clf__max_features                 = 0.9,\n",
    "                             #clf__min_impurity_decrease        = 1e-5,\n",
    "                             #clf__class_weight                 = {0:1,1:3},                                 \n",
    "                             clf__bootstrap                    = True,\n",
    "                             clf__n_jobs                       = 50,\n",
    "                             clf__criterion                    = 'gini'\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfcls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rfcls  = pipeline.set_params(clf__n_estimators                 = random_search.best_params_['clf__n_estimators'],\n",
    "#                              clf__max_leaf_nodes               = random_search.best_params_['clf__max_leaf_nodes'],\n",
    "#                              clf__min_weight_fraction_leaf     = random_search.best_params_['clf__min_weight_fraction_leaf'],\n",
    "#                              clf__max_depth                    = random_search.best_params_['clf__max_depth'],\n",
    "#                              clf__max_features                 = random_search.best_params_['clf__max_features'],\n",
    "#                              clf__min_impurity_decrease        = random_search.best_params_['clf__min_impurity_decrease'],\n",
    "#                              clf__class_weight                 = random_search.best_params_['clf__class_weight'],                                 \n",
    "#                              clf__bootstrap                    = random_search.best_params_['clf__bootstrap'],\n",
    "#                              clf__n_jobs                       = 40\n",
    "#                              clf__criterion                    = 'gini'\n",
    "#                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfcls.fit(X_train_meta.astype(dtype=np.float32), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_meta=pd.DataFrame(imp.transform(X_test), columns=X_test.columns)\n",
    "y_pred = rfcls.predict(X_test_meta)\n",
    "\n",
    "recall_ts, precision_ts, f1_ts =  get_metrics(y_pred.astype(int), y_test.astype(int))\n",
    "                                                  \n",
    "print('Hold Out: ')\n",
    "print('Precision: %7.5f, Recall: %7.5f, F_1: %7.5f' % \n",
    "(precision_ts, recall_ts, f1_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del X_test_meta, X_train_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn import over_sampling\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, \\\n",
    "                            classification_report, precision_score, \\\n",
    "                            recall_score, roc_curve, precision_recall_curve, \\\n",
    "                            average_precision_score, make_scorer, confusion_matrix, get_scorer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 76 constant columns\n"
     ]
    }
   ],
   "source": [
    "zero_std_cols = df_part.columns[df_part.std(axis=0) == 0.].values.tolist()\n",
    "df_part.drop(columns=zero_std_cols, axis=1, inplace=True)\n",
    "print('Removed {} constant columns'.format(len(zero_std_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp=SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "df_part_meta=pd.DataFrame(imp.fit_transform(df_part.astype(dtype=np.float32).values), columns=df_part.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(df_part_meta.drop(['target'], axis=1), df_part_meta.target, \n",
    "                 random_state=42, shuffle=True, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 4612709, 1.0: 2259592})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_part.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48986224797618927"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, p = df_part.target.value_counts().tolist()\n",
    "p/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adasyn = over_sampling.BorderlineSMOTE(sampling_strategy=0.6, \n",
    "                                   random_state=np.random.RandomState(42), \n",
    "                                   k_neighbors=5,\n",
    "                                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_pipe = joblib.load('./pkl/xgb_cls_tuned_pipe_wFT_200606.pkl')\n",
    "xgb = cls_pipe['clf']\n",
    "xgb_params = xgb.get_params()\n",
    "classifier = XGBClassifier(**xgb_params)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train_res.astype(dtype=np.float32), y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test.astype(dtype=np.float32))\n",
    "\n",
    "recall_ts, precision_ts, f1_ts =  get_metrics(y_pred.astype(int), y_test.astype(int))\n",
    "                                                  \n",
    "print('Hold Out: ')\n",
    "print('Precision: %7.5f, Recall: %7.5f, F_1: %7.5f' % \n",
    "(precision_ts, recall_ts, f1_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
